\subsection{MicroNet Tools}
\label{sub:tools}

The MicroNet tools are a collection of Eclipse plug-ins. Eclipse was chosen due
to the primary Java nature of MicroNet. This allows to develop Java \mss{} very
quickly. But the MicroNet Tools also offer a solution to integrate other
technologies into a \ms{} application. This language independence is
accomplished by using Json as a low level information exchange format. As long a
a technology supports Json it can participate in the application. Another
requirement is that the technology has access to the message broker.

Since the user interface (UI) of an Eclipse plug-in is written using the Swing
Window Toolkit (SWT) library it can easily be exported to be a standalone tool
decoupled from Eclipse. With this approach it is possible to port the MicroNet
Tools to other Platforms as long as they support a JVM.

The MicroNet Tools have been completely developed within this last semester
thesis and are the major contribution to four of the hypotheses listed in
\autoref{sub:hypothesis}: The composition, deployment, simple development, and 
reproducibility hypotheses.

\subsubsection{Files and Folders Structure}

To allow loose coupling of a \ms{} application the MicroNet makes a few
assumptions on how to organize files and folders:

\begin{itemize}
  \item The eclipse workspace folder must contain one project folder for each
  \ms{}
  \item For automated integration of a \ms{} its project folder must be either a
  Java/Maven project or must contain a Dockerfile.
 \item One shared folder to exchange the Shared Model and the Service API must
 be present
\end{itemize}  

\begin{figure}
	\centering
	\includegraphics[width=9cm]{images/tools/folder_structure}
	\caption{Example folder structure of a MicroNet application workspace.}
	\label{fig:folder_structure}
\end{figure}

\autoref{fig:folder_structure} shows an example folder structure of a MicroNet
application workspace. The shared folder in this case is simply a folder within the
workspace. The figure also shows three canonical examples of project folders.
The AccountDB folder represents a containerized PostgreSQL database. The
AccountService folder is a standard MicroNet Maven/Java service project. The
activemq folder contains only a Dockerfile which is the minimal requirement to
participate in a MicroNet application.

\subsubsection{Annotations}

MicroNet annotations provide a solution to define a \ms{} in a very lean way.
A service is defined by annotating a arbitrary class in the service projects
with the \textit{@MessageService(uri=``mn://service\_name'')} annotation. Within
the service class listener methods can be annotated with the
\textit{@MessageListener(uri=``/api\_method'')} annotation to define the
reactive behaviour of the service according to the defined API. Examples of
services defined by the annotation can be seen in
\autoref{lst:service_communication} and \autoref{lst:message_parameters}.

\begin{figure}
\begin{lstlisting}[language=Java,firstnumber=1] 
@MessageService(uri = "mn://foo")
public class ServiceFoo {
	@OnStart
	public void onStart(Context context) {
		System.out.println("Start called");
	}
	
	@OnStop
	public void onStop(Context context) {
		System.out.println("Stop called");
	}
	
	@MessageListener(uri="/hello")
	@RequestPayload(UserValues.class) 
	@ResponsePayload(CredentialValues.class)
	@RequestParameters({
		@MessageParameter(code=ParameterCode.ID, type=Integer.class),
		@MessageParameter(code=ParameterCode.NAME, type=String.class)
	})
	@ResponseParameters({
		@MessageParameter(code=ParameterCode.ID, type=Integer.class),
	})
	public Response helloHandler(Context context, Request request) {
		int idParameter = request.getParameters().getInt(ParameterCode.ID);
		String nameParameter = request.getParameters()
			.getString(ParameterCode.NAME);
		
		UserValues user = Serialization.deserialize(
			request.getData(), UserValues.class);
		System.out.println("Process: " + user + " and " + nameParameter);

		String responseData = Serialization.serialize(user.getCredentials());
		Response response = new Response(StatusCode.OK, responseData);
		response.getParameters().set(ParameterCode.ID, idParameter);
		return response;
	}
}
\end{lstlisting}
\caption{A fully defined MicroNet \ms{} including all possible pre- and
post-condition annotations.}
\label{lst:pre_post_conditions}
\end{figure}

MicroNet annotation also provide a basic implementation of the design by
contract pattern. A service defines preconditions on request payloads and
defines post-conditions on response payloads. This system aims to prevent
semantic errors in communications. The pre- and post-conditions build the
foundation of the Code Assist tool of MicroNet which aids the developer in
preventing mistakes in \ms{} communication design.
\autoref{lst:pre_post_conditions} shows a \ms{} defined by annotations
containing a well defined message listener with all pre- and post-conditions. It
has to be mentioned that the Request/ResponseParameter annotations could
implicitly be generated by parsing the abstract syntax tree of the listener
method. This is however a very advanced topic which could fill a whole thesis by
itself.
 
 \paragraph{Annotation Processing}
 
Java Annotations can be either be used during run-time or processed during
compilation-time. MicroNet only processes annotations at compile-time. Since
Java version 6 the annotation processing process is tightly integrated into the
standard Java build process. This makes the annotation process platform
independent and can be reproduced in a command line java build, a Maven build or
an Eclipse build\footnote{Annotation processing is executed by the Java compiler
which behaves slightly different for all evaluated build setups (Eclipse, Maven,
or java native). Specifically newly generated annotations are only found by the
Eclipse proprietary compiler}.

The annotation processing process is also the entry point for code generation.
Even if no annotation are present in a project annotation processing can
still be activated to just generate the Shared Model and without generating any
service implementation. The MicroNet annotation processor provides an option for
this purpose.

\subsubsection{Code Generation}

Code generation allows the developer to omit the boiler plate code that is
needed to integrate a service in a MicroNet application. This covers the setup
of the appropriate networking solution according to the environment and the
generation of the executable class of the \ms{}. This simplification allows the
developer to focus more on the actual domain logic of the \ms{}. It also spares
the developer in having to register the main service class within the
application. The service class is found automatically and the registration is
done implicit by the annotation processor.

The code generation library of MicroNet is very slim and can be translated to
other programming languages very easily if needed. Since code generation is
basically nothing more then generating the right ``text-files'' this can be
accomplished in almost any imaginable programming language.

The MicroNet code generation library is implemented using the Java Poet
library. Java Poet allows for typesafe generation of Java classes and is very
easy to use. 

\paragraph{Service Generation}

The \textit{@MessageService} and \textit{@MessageListener} annotations are used
to build the executable class of a \ms{}. The executable class registers all
message listeners with the networking system. In addition the annotated @Start
and @Stop methods are called at service start respectively at service
termination. The generated main method encompasses the start/stop functionality
and the listener registration in a defined set-up sequence.
\autoref{lst:generated_service} shows the generated implementation of the
annotated service shown in \autoref{lst:pre_post_conditions}.

\begin{figure}
\begin{lstlisting}[language=Java,firstnumber=1] 
public final class ServiceImpl {
  public static void main(String[] args) {
    try {
      System.out.println("Starting ServiceFoo...");

      IPeer peer = PeerFactory.createPeer();
      Context context = new Context(peer, "mn://foo");
      ServiceFoo service = new ServiceFoo();

      System.out.println("Registering message listeners...");
      peer.listen("/hello", (Request request) -> 
      	service.helloHandler(context, request));

      System.out.println("ServiceFoo started...");
      service.onStart(context);

      Runtime.getRuntime().addShutdownHook(new Thread() {
        @Override
        public void run() {
          System.out.println("ServiceFoo stopped...");
          service.onStop(context);
        }
      });
    }
    catch (Exception e) {
      System.err.println("Could not start ServiceFoo...");
      e.printStackTrace();
    }
  }
}
\end{lstlisting}
\caption{A executable \ms{} main class generated out of an annotated service
class.}
\label{lst:generated_service}
\end{figure}

\paragraph{Model Generation}

The model generation process is completely independent from the service
generation and is used to translate the game model which is defined in Json to
java POJOs (plain old Java objects). Because the MicroNet Model generation
library is very slim it can also be reproduced in other programming languages
with relative ease. \autoref{lst:generated_model_class} shows the
\textit{UserValues} POJO generated out of the corresponding type template shown
in \autoref{lst:template_type}.

\begin{figure}
\begin{lstlisting}[language=Java,firstnumber=1] 
public class UserValues {
  private int id;
  private CredentialValues credentials;

  public void setId(int id) {
    this.id=id;
  }

  public int getId() {
    return id;
  }

  public void setCredentials(CredentialValues credentials) {
    this.credentials=credentials;
  }

  public CredentialValues getCredentials() {
    return credentials;
  }
}
\end{lstlisting}
\caption{The UserValues POJO created out of the corresponding model template.}
\label{lst:generated_model_class}
\end{figure}

The challenge for model generation is not the generation process itself but the
definition and editing of the model that is generated and its representation.
These aspects make up a much larger part of MicroNet then the actual code
generation. Model editing and representation is further discussed below in the
paragraph Model Editor.

\subsubsection{Code Assist}

The Code Assist plug-in helps the developer to keep track of functionality
provided by other services. It presents the Shared API in a type-safe way to
the developer by relying on the pre- and postconditions defined by MicroNet
annotations.

Code Assist is implemented by using the Eclipse code-completion extension point.
This extension point allows to add custom entries to the code completion list
box. This functionality is used to offer the MicroNet API to the developer any
time he types \textit{``mn://''} in a source file. The proposals are filtered
according to the developer's input.

Type-safety enforcement is currently not implemented in MicroNet due to the same
reason as mentioned above in section Annotations that it requires parsing the
\ms{} code. It could however be implemented by searching the AST of a message
handler method for references on the request and response objects. Calls to to
\code{getParameters()} or \code{setParameters()} can be be analyzed in regard to
which \code{ParameterCode}s are used and of which template type the parameter
is. This feature would allow the developer to omit the
\code{@RequestParameters} and \code{@ResponseParameters} annotations.

Upon violation of the message types the compiler can generate an error which
forces the developer to fix the issue before a build can be executed.
Although possible the implementation of violation detection again involves
parsing the Java AST and this effort is out of the scope of this
thesis.

In the current version of MicroNet the types are presented to
the developer via a tool-tip. Although type-safety is not
enforced the developer at least sees the correct types in the
code assist tool-tip which alone is already very helpful.

\todo{screenshot}

\subsubsection{Service Explorer}

The service explorer is the central management UI of a MicroNet and helps the
developer to get an overview over the whole game application. The service
explorer is realized using a custom Eclipse view. The view contains a list of
all services showing their versions along with other useful information
like required ports or links to other services. The service explorer displays
services which are Java, Maven and Docker projects. The service list is dynamic
and refreshed automatically when projects are created or deleted.

The service list can be used to quickly edit the configuration of services. This
includes the port configuration as well as service linkage for the Docker
overlay network.

The service explorer is also used to configure the composition of the
application in a visual way. Services can be activated to be part of the build
process which automatically integrates them in the composition files (Maven:
pom.xml, Docker: docker-compose). This is done by selecting for each service
individually if is part of the Maven build and/or part of the Docker container
build process.

The service explorer also provides a quick interface to all launch
configurations explained in the Launch Utility section below. The launch
functionality is provided with a context menu for each service in the list and
through the local pull-down menu offered by the Eclipse view.

\todo{screenshot}

\subsubsection{Launch Utility}

The launch utility brings order to the vast different possibilities of how to
orchestrate \ms{} application with containers. Many different configurations can
be helpful to develop, test and deploy a \ms{} application. The MicroNet launch
tools provide an easy way to set-up and start launch configurations.

The launch configurations of a Java/Maven build are offered via the Eclipse
Launcher plug-in. For these configurations the MicroNet launch utility only has
to run the respective Eclipse Launch configuration. 

The automation of the Docker container build process is not as simple because
eclipse offers not built in functionality to access the Docker daemon. The
Docker Tools for Eclipse can be used since it provides the necessary Launch
configurations. This however introduces a strong dependency on the Docker Tools
which is undesirable. Many client for the Docker daemon exist to integrate
Docker automation into applications. This however introduces another dependency
closely related to Eclipse and also the tested Spotify Docker client which looks
very promising caused several class path run-time errors and does not support
Docker compose. 

A workaround is to automate the Docker CLI using the Java run-time environment.
With this approach the docker commands are simply executed on the host of the
virtual machine. This decouples the the docker integration mainly from Eclipse
and places it into the used Docker CLI. A Docker CLI is available for all major
platforms: Linux, Windows and MacOS. Since the docker CLI commands are the same
on all system this is a very platform independent approach since it relies only
on a JVM and the docker CLI, which is installed alongside Docker anyway. A
Drawback is that the developer has to configure the host-path to the docker
CLI executables. This is complicated further when Docker Toolbox is used instead
of native Docker since it requires setting several Docker environment variables.
The MicroNet launch Utility encompasses all this functionality.

The launcher can deploy MicroNet applications in three distinct ways which are
combinable which each other: Local native, Local containerized, and cloud
containerized. \todo{autoref launcher picture} shows how the launch
configurations can be started via the service explorer. The rest of this
paragraph explains all three deployment modes.

\paragraph{Local Native}

\begin{figure}
	\centering
	\includegraphics[width=10cm]{images/architecture/DeploymentLocalNative}
	\caption{Local native deployment of a MicroNet driven application.}
	\label{fig:deployment_local_native}
\end{figure}

The native configuration runs or debugs a game application as a set of native
Java applications. This makes debugging very fast and the integration in Eclipse
provides many useful debugging tools. To launch multiple Java applications at
once the CDT Launch Group plug-in is used. It composes multiple launch
configurations into a single configuration. Upon Launch Group execution all
contained applications are started individually. No build step is needed for
this configuration.

For the native configurations it is easiest to run dependencies as standalone
installations on the host. Since the native configuration is solely used during
development this allows to also test the dependencies isolated from the composed
application. Non the less it is possible to combine a local native configuration
with a local containerized configuration. Services and dependencies can
therefore be started in the configuration best suited for them. 

\autoref{fig:deployment_local_native} shows the deployment of a MicroNet
driven game in local deployment mode.

\paragraph{Local Containerized}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{images/architecture/DeploymentLocalContainerized}
	\caption{Local containerized deployment of a MicroNet driven application.}
	\label{fig:deployment_local_containerized}
\end{figure}

The local containerized configuration is meant to reproduce the final deployment
process on the local developer machine. For this purpose Maven and Docker
compose/swarm are used. 

A local Maven build of the complete application is done by aggregating the
individual Maven service projects into a master .pom file. The master .pom can
be used to build the whole application at once. Which services are aggregated to
the master .pom file can be configured via. the service explorer.

A local Docker deployment is defined by a docker-compose file. This file is also
defined by configuring services via the service explorer. The Docker build
process is then is simply invoked by building the docker-compose file.

To run the local containerized application the local docker engine can be used.
Docker-compose is installed native with most docker installations or can be
installed separately. If the application is started using either Docker-compose
or docker swarm commands. On the local developer machine there is only little
difference between docker-compose and -swarm. However specifically networking is
different and therefore both deployment approaches should be tested locally.

\autoref{fig:deployment_local_containerized} shows how an application is
composed and deployed in local containerized mode.

\paragraph{Cloud Containerized}

\begin{figure}
	\hspace*{-0.8cm}
	\centering
	\includegraphics[width=1.1\textwidth]{images/architecture/DeploymentCloudContainerized}
	\caption{Cloud containerized deployment of a MicroNet driven application.}
	\label{fig:deployment_cloud_containerized}
\end{figure}

The final step of \ms{} application deployment is cloud deployment. The idea
behind application containerization is that this process is meant to be
reproducible deterministically on different systems. Therefore if the
application is working in the local containerized configuration the cloud
configuration can be achieved very similar.

MicroNet does not provide any out-of-the box solution to deploy an application
in the cloud automatically. This is because of the variety of different
infrastructures that can be used to deploy MicroNet. But the deployment is
prepared by MicroNet so it can be done with very console commands via SSH.

Due to the restriction mentioned in \autoref{sub:zero_buget} the production
environment of \mn{} is a virtual Linux server in the HSR cloud. The cloud
deployment process is mainly based on this environment. Since this a very
general setup the process can easily be reproduced on other environments.

In order to deploy a MicroNet \ms{} application the developer must perform the
following steps under the assumption that the server runs a fresh Linux
installation.

\begin{itemize}
  \item Install: Docker Engine, Java, Maven and Git
  \item Initialize docker swarm (master and worker machines)
  \item Pull the game application repository via Git (containing all service
  projects and the shared folder)
  \item Build the application class files using the master .pom file (annotation
  processing and code generation is performed during this step)
  \item Containerize the application using docker-compose API and the generated
  docker-compose file
  \item Launch the application in Docker Swarm using the docker stack API 
\end{itemize}

This sounds like a lot of steps but in fact the process is reasonably quick and
only requires very few console commands which can be looked up in the MicroNet
documentation \cite{micronet2017doku}.
\autoref{fig:deployment_cloud_containerized} gives an impression on how such a
docker-swarm environment may look like.

\subsubsection{Model Editor}

The model editor is the last feature that was introduced in MicroNet tools. It
is the final solution on how to cope with logical \ms{} composition in a visual
way. Since the game model is of very theoretical nature it is not suited to be
edited directly in its underlying Json format. Because of this the model editor
is especially important to allow convenient editing of the game model underlying
a game application.

The model edit is basically a graph editor visualizing a direct representation
of the game graph to allow to extending and changing the graph. The graph has
three root nodes for which each span a model tree.

\paragraph{Parameter Code List}

The parameter code tree is simply a flat list of String constants which defines
all parameter codes used throughout the application. This global approach allows
to substitute the parameter codes strings with numbers which is more space
efficient. Since parameters are used very often this has a noticeable impact on
bandwidth requirements.

The datatype of the parameters is defined by using templates of the shared
model.

\paragraph{Template Tree}

The template tree allows to edit the game type graph. Object Types defined using
the template tree can be used for message transfer and persistence. Templates
are descriptions of domain objects that can be used to generate data classes
using code generation.

A template consists of a set of fields of the following types: STRING, NUMBER,
BOOLEAN, CHAR, ENUM, LIST, SET, MAP, and COMPONENT. The types are derived from
the Java types since they are well documented and can be redefined in other
programming languages using the Java language specification.

The COMPONENT type can be any other template type. In this case the component is
contained in the data class as a struct and not as a reference. Also template
types can be derived from other templates. This is realized using Java
inheritance.

\paragraph{Prefab Tree}

The prefab tree is the ``physical'' representation of the game graph. It
contains actual instances of template types. This can be used by game designer
to pre-define game objects. The prefab tree is directly compatible with the
serailization component provided by MicroNet. This allows services to use the
generated model to directly serialize and de-serialize game objects from the
database or from payloads and parameters during message transfers.

The prefab tree can either be persisted in the file-system or persisted in the
database. Either way the prefab approach allows for very convenient and
consistent handling of game data.

