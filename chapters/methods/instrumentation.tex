\section{Instrumentation}

As a first step to examine the subjects defined in \autoref{sec:subject_pool} a
clear definition of the technical foundation to reproduce the subjects during
the lab research (\autoref{sub:lab_reserach}) has to be made. For this purpose a
comparison of available technology is provided along with a proposal on how to
choose between similar available technologies.

\subsection{MicroNet: A Reference Implementation}

The prototype that has been already mentioned prior \todo{Exact reference}
several times is actually a collection of prototypes representing a reference
implementation on how to realize an \og{} using \ms{}.

The development title of this reference implementation is MicroNet.
MicroNet consists of the following components:

\begin{itemize}
  \item A core framework that provides run-time libraries required to operate a
  \ms{} \og{} application cluster.
  \item A small reference implementation on how to build an \og{} with MicroNet
  \item A service catalogue which contains reference implementation of
  functionality that is commonly uses in \ogs{}.
  \item A tool-set to simplify the development process of an \og{} 
\end{itemize}

\subsubsection{Common Functionality}

The polyglot programming tenet states that a \ms{} is free to choose its
implementation details. For the actual realization of a \ms{} application
this aspect introduces a number of challenges. 

It breaks the DRY (don't repeat yourself) principle if the same piece of
functionality is simply copied among multiple services. To cope with this a
solution is needed that on one hand does respect the DRY principle and on the
other hand provides a mechanism to share similar functionality among services.

One solution for this dilemma is to provide a reference solution that furnishes
a service with common functionality. This reference solution can be used to
build \mss{} which have no special technology requirement quickly.

In the prototype this aspect is tackled using a reference implementation
developed in Java. Java is in theory platform independent and therefore a good
choice to provide a general solution for \mss{} application design and
implementation. \mss{} with extended requirements are free not to rely on the
common solution and participate in the cluster autonomous.

\subsubsection{Application data}

As explained in \autoref{sub:games} an \og{} game operates on data. This data
must be suitable to be persisted and to be sent over a network (these aspects
have been discussed in project thesis 2 \todo{ref}). There is an literally
infinite number of ways on how to treat application data like for example Json,
XML, CVS, Strings, binary data, and HTML just to name a few.

Since \ogs{} are very time critical the fastest and therefore a binary data
format would introduce the least overhead. But since binary serialization
introduces a large amount of additional work during development it can be
considered an optimization\cite{gafferon2017games} and therefore a simpler data
format can be chosen for the prototype. Json is a good compromize in this regard
because it has an acceptable overhead, is human readable and also very popular.

\subsubsection{Networking}

An integral part of \ogs{} is networking. In regards of \mss{} the most common
approaches to networking are RESTful HTTP or Messaging. Messaging offers
several advantages over pure HTTP that are quite useful to make a \ms{}
application robust: Message queues are persistent and in case a service is
unavailable the messages are buffered and delivered as soon as the service
is available again. Furthermore it is possible to combine multiple message
brokers to a mesh to provide fail-over functionality. These aspects make a
message broker the optimal choice to facilitate networking for \ms{} \og{}
applications. Networking has been discussed in detail in project thesis one
\todo{Cite Thesis 1}.

\subsection{Development Environment}

The decision to propose Java as the main programming language for \mss{} allows
to derive a set of assumptions that simplify the development process of \ms{}
applications.

\subsubsection{Java as the Main Programming Language}

The latest Java version 8 introduced functional programming into Java. With
functional programming it is possible to inject code into methods in a
convenient way. They are a perfect match to allow the developer to inject his
own code into a framework. MicroNet makes excessive use of this possibility.

Java enables the utilization of Apache Maven which is a very powerful software
project management and comprehension tool. It allows the describe and automate
the build process of a java applications. It also simplifies the process of
integrating third party java libraries into the application and the majority of
the java libraries are available as maven artifacts.

\subsubsection{Code Generation}

Java version 6 introduced annotation processing in the standard java build
process. This makes it very simple to provide framework functionality closely
related to the actual \og{}. Annotation processing coupled with code generation
are one major driver to facilitate the composition of \mss{}.

\subsubsection{The Eclipse IDE}

When it comes to Java development the Eclipse IDE is very popular. This is
backed by the fact that Eclipse has been around since \todo{Date} and has gone
though a long maturing process. Meanwhile Eclipse is a very robust development
environment not only for Java but also for many other programming languages. 

The way Eclipse is built makes it very easy to extend it. It is basically a set
of plug-ins that together form the IDE. The developer can write it's own
plug-ins to tailor the development process to his needs. 

MicroNet uses the Eclipse plug-in functionality to integrate \ms{} specific
development tools into Eclipse. With mininal effort it is also possible to
extract the MicroNet plug-ins to standalone applications. This however is out of
scope for this thesis.

\subsection{Container Engine}

Containers are a very powerful modern approach to run software. Instead of
installing a software directly on a host it is instead installed in a container.
The container can then run among other containers in a container engine as a
virtual machine. The container engine can be installed on any host that is
supported. This approach greatly increases the portability of software and
allows developers to build software once and run it anywhere as long as the
container engine is available.-

\subsubsection{Docker}

Docker is the most widely used container technology and a de-facto standard
\todo{Citation needed}. The docker ecosystem provides with Dockerhub a central
registry for available Docker containers. This centralized approach makes is
easy to install required dependencies on a system as long as docker is
installed.

\paragraph{Docker Compose}

Docker Compose is a way to describe a complex application consisting of multiple
Docker containers. With this approach it is possible to build or run a complete
\ms{} application with a single command. The structure of docker-compose is
also very well suited for automation. The compose script is in yaml format which
many libraries support.

Docker Compose is also the foundation to deploy a distributed application in
Docker Swarm explained in \autoref{sub:composition_engines}.

\paragraph{Docker for Windows}

As mentioned in \todo{Ref to Windows Requirement} the whole \og{} development
process must be realizable in Windows. Fortunately the Docker for Windows Client
is a very sophisticated tool that feels very close to the original Docker
version on Linux. One problem regarding Docker for Windows is that it does not
run on Windows versions which do not support HyperV. As a work-around developers
can use the Docker Toolbox. Docker Toolbox uses VirtualBox to provide the
same functionality as stand alone Docker but with the price of a little bit more
complexity during setup.

\subsection{Cloud Service Providers}

Meanwhile is very popular for a company to use the infrastructure of the major
cloud service providers to deploy their infrastructure \cite{roberts2016aws}
\cite{pronschinske2015turbine}. This offer a stability and performance that 
cannot be achieved by a proprietary server center \cite{gai2012towards}.

Because of this trend it is mandatory to take largest players in this market
as a reference on how to deploy modern distributed applications. Therefore the
usability of a technology is partially dependent of the integration solution for
the major cloud providers. Amazon Cloud (AWS) and Google Cloud Platform (GCP)
are the major cloud service providers that are considered in this thesis.

It has to be mentioned that due to the limitation mentioned in \autoref{sub:zero_buget}
these cloud service providers cannot be examined in practice. However the
comprehensive documentation of these providers allows to gain an insight into
their technology.

\subsection{Composition Engines}
\label{sub:composition_engines}

The physical \ms{} composition topic is a pure technology evaluation problem.
The selection of technologies for evaluation is the first aspect to consider in
this regard. Among the many available solution the three well known solutions
for \ms{} composition are compared: Kubernetes, Apache Mesos and Docker Swarm.

\subsubsection{Evaluation Criteria}

In order to compare these three composition solutions X properties are examined
for each technology. The categories are chosen according to the experience of
cloud experts in the industry \cite{toll2016cloud_expert_eval}
\cite{lerilli2012cloud_eval_criteria} \cite{voras2011evaluating}.

\paragraph{The Virtualization Layer}

The virtualization technology used to operate a cluster of \mss{}. The
virtualization technology is tightly coupled with the different Eco systems the
technology supports.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -Pods are the smallest unit that make up a deployment. A pod is one
    autonomous unit of the application stack. They can confine one or more
    containers.
    
    -Supports AWS, GCP (using the Coogle Compute Engine - GCE), Microsoft Azure,
    Joyent, OpenStack, VMWare, bare metal and localhost deployments.
    
    -Minikube is a way to run and test Kubernetes localhost deployments. It
    supports the VM drivers: virtualbox, vmwarefusion, kvm, and xhyve.
    
    -CoreOS is a way to install Kubernetes on bare metal.&
    
    -Mesos consists of a master daemon that manages agent daemons running on
    each cluster node. Each daemon can run containers as tasks. 
    
    -Mesos supports Docker containers but also offers a proprietary solution in
    the form of Mesos Containerizers. solution.
    
    -With Mesosphere DC/OS (the datacenter operating system) bare metal
    installations are possible. &
    
    -Multiple Docker Daemons on different physical machines to provide a cluster
    of nodes.
    
    -Docker Daemons are available for Windows, MacOS, and Linux. Under Linux
    Docker is realized with native Linux Containers. The native Windows
    installation uses HyperV.
    
    -Docker Toolbox provides a way of using Docker with virtualbox.
    
    -Docker Daemons are also available for AWS and Azure.\\
    \hline
  \end{tabular}
\end{center}


\newpage
\paragraph{The Storage Layer}

Since container live only non-permanently in memory the composition engine must
provide a way for containers to persist data that exceeds the lifetime of a
container. The storage layer is also provides the possibility to share data
among containers.

Polyglot database solutions often use containers to run DBMS system. The storage
layer provided by the composition engine is then used to persist the data on
disk.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -Kubernetes uses an approach called Persistent Volumes to provide a common
    API to manage the storage layer. 
    
    -Supports the storage technologies of: GCP, AWS, Azure, NFS, Vsphere,
    VMware and more.&

    -It is suggested to use accessible storage outside the containers for
    example a database (NoSQL/SQL)
    
    -Offers Persistent Volumes comparable to the local filesystem. They
    live on after a task terminates and other tasks can consume the persisted
    data during execution.
    
    -The Docker Containerizer supports the Docker Volume Plug-in & 
     
    -Host-Based persistence allows multiple containers to one shared volume
    bypassing the union file-system. Data corruption can be the consequence.
    
    -Implicit Per-Container Storage is a storage sandbox per container on
    the host. When a container is removed, so is it's sandbox.
    
    -Explicit Shared Storage (Data Volumes) mounts an explicit location on the
    host within one or more containers allowing shared read-write access to
    a common directory.
    
    -The dependency on the host file-system makes containers non portable. To
    cope with this it is possible to provide Data Volumes though a shared
    file-system like Ceth, GlusterFS, or NFS and expose it though a consistent
    namespace.\\
    \hline
  \end{tabular}
\end{center}

\newpage
\paragraph{The Management Layer}

The management layer is responsible to provide an interface to run application
stacks or single containers in the virtualization layer.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
  	\hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -kubectl is the main command line tool to control a Kubernetes cluster.
    
    -kubefed is a command line tool to federate multiple clusters

	-minikube is a command line tool to administrate localhost clusters
    
    -The Web UI (Dashboard) offers a graphical user interface to manage nodes,
    deployments, and volumes in the cluster 
    
    -Kompose tool to translate docker-compose applications&
    
    -Specific Tools DevOps and Developers
    
    -Several API client libraries to control the cluster 
    
    -No graphical user interface to manage the cluster is available out of the
    box&
    
    -docker-compose command line tool to describe and build containerized
    applications
    
    -docker stack command line tool to manage an application stack 
    
    -No graphical user interface to manage the cluster is available out of the
    box\\
    
    \hline
  \end{tabular}
\end{center}

\paragraph{Provisioning Time}

The initial provisioning time and time to scale up and down the application.
For detailed data on this property the provisioning time that is needed to
deploy the demo application on all technology stacks can be measured.
These measurements include the time needed to understand the documentation to a
sufficient extent as well as the time needed to install the necessary software
and to deploy the demo application.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    $<$ 3 days & Not Evaluated & $<$ 1 day \\
    \hline
  \end{tabular}
\end{center}

\newpage
\paragraph{Ease of Use}

The impression of simplicity that the deployment of the demo application
causes.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -The dashmoard is a easy to understand way to use the Kubernetes cluster.
    
    -On Windows the setup of minikube is cumbersome.
    
    -Kubernetes proprietary scripts are complicated and hard to get right &
    
    
    -Mesos is hard to set up because of it's set of dependencies like Zookeeper
    or the different schedulers.
    
    -Ease of operation is not evaluated for Mesos& 
    
    -When Native Docker is understood by the developer Docker Swarm is very
    easy to understand
    
    -Docker Swarm is very slim, so a full picture of the technology can be
    gained very quickly.\\
    \hline
  \end{tabular}
\end{center}

\paragraph{Reduction of Technology Complexity}

The reduction of technology complexity is considered in regard to networking
among container, persistent storage among containers and the effort needed to
integrate dependencies in a application.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -The Web UI provides with services and descovery, workloads, and persistent
    volumes a convenient way to abstract core tenchnologies.
    
    -Dependencies can be abstracted using dedicated containers. Containers are
    made available using private registries or the Google, Amazon or Azure
    Container Registries.&
    
    -The agents have to be configured according to networking and storage.
    
    -Containers can be used to abstract dependencies. & 
    
    -The Docker Engine allows to define overlay networks. This aspect of
    Docker is not trivial and requires knowledge in regards to overlay
    networks.
    
    -Persistent storage and networking can be defined via the docker-compose
    file.
    
    -Dependency abstraction is provided by Docker-hub, a central docker image
    repository. Docker hub is not restricted to Docker-Swarm.\\
    \hline
  \end{tabular}
\end{center}

\newpage
\paragraph{Infrastructure Monitoring and Reporting Ability}

The ability to observe a running \ms{} application stack. This includes alerts
on abnormal situations as well as the visual representation of statistics and
metrics.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -Heapster as a cluster-wide aggregator of monitoring and event data.
    
    -cAdvisor as an open source container resource usage and performance
    analysis agent. 
    
    -A Grafana setup with InfluxDB as a very popular combination for monitoring&
    
    -Mesos nodes report a set of statistics and metrics that
    enable cluster operators to monitor resource usage and detect abnormal
    situations early.
    
    -Observability metrics in the following categories are available:
    Resources, Masters, Agents, Frameworks, Tasks, Messages, Event queues
    and more& 6
    
    -Does not provide a built-in solution for reporting.
    
    -Depends on the underlying infrastructure for reporting.
    
    -Grafana in addition to cAdvisor and Prometheus can be used to implement an
    open source reporting and monitoring solution.\\
    \hline
  \end{tabular}
\end{center}

\paragraph{Customization}

The ability to provide new functionality or change existing behaviour. 

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -Custom API types allow to define new resource that the user wants to add to
    the Kubernetes API 
    
    -Add-ons can be used extend the functionality of Kubernetes.
    
    -Network plug-ins are currently in alpha.& 
    
    -Allows to add custom framework schedulers in C++, Go, Haskell, Java, Python
    and Scala
    
    -RENDLER provides as example framework implementation & 
    
    -Extensions possible using the Docker Engine managed plug-in system
    
    -Provides SDKs for Docker Engine API in Python and GO. These APIs are tested
    by Docker maintainers.
    
    -Third party libraries in: C/C++, C\#, Java, and more.\\
    \hline
  \end{tabular}
\end{center}

\paragraph{Exclusivity}

How easy is it extract your legacy data, upon a technology change or upon
deprecation of a technology?

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -Proprietary solution prevents direct re-usage of an application stack. & 
    
    -Mesos Containerizers are not portable but Docker Containerizers are. &
    
    -The full application stack can be translated to another technology very
    easily due to Docker base technology nature.\\
    \hline
  \end{tabular}
\end{center}

\paragraph{Application Description Format}

The format that is used to describe an application stack.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -Kubernetes deployment description in .yml format & 
    
    -Task Group API & 
    
    -docker-compose file in .yml format. \\
    \hline
  \end{tabular}
\end{center}

\paragraph{Scalability}

The ability of the technology to scale an application stack according to
performance requirements.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -Horizontal Pod auto-scaling allows Kubernetes to automatically scale the
    number of pods based on observed CPU utilization. & 
    
    -CD/OS provides auto-scaling with Marathon & 
    
    -Provides no auto-scaling mechanism but manual scaling is very simple and
    can therefore me automated.
    \\
    \hline
  \end{tabular}
\end{center}

\paragraph{Liecence}

The licence the technology is released under.

\begin{center}
  \begin{tabular}{ | p{4.5cm} | p{4.5cm} | p{4.5cm} | }
    \hline
    \textbf{Kubernetes}&\textbf{Apache Mesos}&\textbf{Docker Swarm}\\\hline
    -Apache License 2.0 & 
    
    -Apache License 2.0 & 
    
    -Comunity Editon (free) 
    
    -Enterprise Edition with a per node / per year fee\\
    \hline
  \end{tabular}
\end{center}
 
\subsection{Database Solution}
\subsection{Source and Artifact Control}
\subsection{Cloud Service Provider}

MicroNet is designed to run in the cloud. It is therefore mandatory to evaluate
the major cloud service infrastructure providers according to their usability
for online games.

One problem in regards to these service providers is payment. Although they
provide a free tier to test their infrastructure, a credit card has to be
pledged as security. In the case the limit is overdrawn a fee will be charged.
This risk cannot be taken in this thesis. 

\subsubsection{Google Cloud Gaming Solutions}

Google offers a solution to deploy rich online games in the cloud. It basically
a setup for the existing google cloud infrastructure with additional
functionality to to provide build in matchmaking matchmaking. For this purpose
it provides an API that is available in a number of programming languages.

The MicroNet service that provides the matchmaking functionality has to be
altered if the Google solution for matchmaking wants to be used. 

To operate a game driven by MicroNet in the Google Cloud the Google App Engine
can be used to run the services of the MicroNet framework and the Google Compute
Engine can be used to run the game simulation servers. ActiveMQ that is used for
messaging can be used with Google Cloud by using Bitnami.

\subsubsection{Amazon Game Lift}

Amazon GameLift is very similar to Google Gaming Solutions. It also provides a
matchmaking solution and the option to communicate with the game backend running
in the Amazon cloud. An advantage of the amazon solution is that it provides an
API for all the major game engines like Unity3D or Unreal Engine 4. Amazon also
provides its own game engine with the name Lumberyard.

\subsubsection{A Dedicated Server}

The most general way to deploy the MicroNet framework is on a dedicated server
hardware. This could be either a cluster of bare metal servers with a sufficient
networking capabilities or a set of virtual servers running somewhere in the
cloud. Either way the result is a set of hosts running linux and have a public
ip address.

For this thesis a virtual server at the HSR will be the test setup. This
infrastructure is also available at the major cloud service providers.



\subsection{Game Engine}

\subsection{The Spacegame Prototype}

